{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karimhatem12/Speech-Emotion-Recognition-/blob/main/Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JspCH3lVUuUG"
      },
      "source": [
        "# **Speech Emotion Recogition (Classification) in real-time using Deep LSTM layers**\n",
        "### ***A Deep Learning LSTM based model with keras.***\n",
        "---\n",
        "\n",
        "### Final project (B.Sc. requirement)  \n",
        "Development by **Karim hatem hamed.**\n",
        "\n",
        "Instructor: **Dr. Eslam Elshaarawy**\n",
        "\n",
        "Computer Science.\n",
        "\n",
        "MSA Universty , Egypt.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4RcjQMCV89B"
      },
      "source": [
        "# **LIBRARIES & GOOGLE AUTH**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nYS9qahzAQ_",
        "outputId": "38619b8a-bd4c-415c-fa31-3f42d2a56bf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K31C-zTfZdFa"
      },
      "outputs": [],
      "source": [
        " %%capture\n",
        "!pip install pydub\n",
        "!pip install pywt\n",
        "!pip install noisereduce\n",
        "!pip install json-tricks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "li2EfZXmQehM"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "from json_tricks import dump, load\n",
        "\n",
        "from pydub import AudioSegment, effects\n",
        "import librosa\n",
        "import noisereduce as nr\n",
        "import pywt\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUMWt35lTQQL"
      },
      "outputs": [],
      "source": [
        "# Emotion kind validation function for TESS database, due to emotions written within the file names.\n",
        "def find_emotion_T(name): \n",
        "        if('neutral' in name): return \"01\"\n",
        "        elif('NEU' in name): return \"01\"\n",
        "        elif('happy' in name): return \"03\"\n",
        "        elif('HAP' in name): return \"03\"\n",
        "        elif('sad' in name): return \"04\"\n",
        "        elif('SAD' in name): return \"04\"\n",
        "        elif('angry' in name): return \"05\"\n",
        "        elif('ANG' in name): return \"05\"\n",
        "        elif('fear' in name): return \"06\"\n",
        "        elif('FEA' in name): return \"06\"\n",
        "        elif('disgust' in name): return \"07\"\n",
        "        elif('DIS' in name): return \"07\"\n",
        "        elif('ps' in name): return \"08\"\n",
        "        else: return \"-1\"\n",
        "        \n",
        " \n",
        "# 'emotions' list fix for classification purposes:\n",
        "#     Classification values start from 0, Thus an 'n = n-1' operation has been executed for both RAVDESS and TESS databases:\n",
        "def emotionfix(e_num):\n",
        "        if e_num == \"01\":   return 0 # neutral\n",
        "        #elif e_num == \"02\": return 1 # calm\n",
        "        elif e_num == \"03\": return 1 # happy\n",
        "        elif e_num == \"04\": return 2 # sad\n",
        "        elif e_num == \"05\": return 3 # angry\n",
        "        elif e_num == \"06\": return 4 # fear\n",
        "        elif e_num == \"07\": return 5 # disgust\n",
        "        else:               return 6 # suprised"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydC8v5SNra-0"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Maximum samples count for padding purposes.\n",
        "\n",
        "sample_lengths = []\n",
        "# folder_path = '/content/drive/MyDrive/Colab_Notebooks/AudioFiles/TESS'\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/Colab_Notebooks/AudioFiles/Used Dataset'\n",
        "\n",
        "for subdir, dirs, files in os.walk(folder_path):\n",
        "  for file in files: \n",
        "    x, sr = librosa.load(path = os.path.join(subdir,file), sr = None)\n",
        "    xt, index = librosa.effects.trim(x, top_db=30)\n",
        "     \n",
        "    sample_lengths.append(len(xt))\n",
        "\n",
        "print('Maximum sample length:', np.max(sample_lengths))               \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WHsU4Noi1n_q"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "tic = time.perf_counter()\n",
        "\n",
        "# Initialize data lists\n",
        "rms = []\n",
        "zcr = []\n",
        "mfcc = []\n",
        "chroma = []\n",
        "emotions = []\n",
        "\n",
        "# Initialize variables\n",
        "total_length = 228864 #228864  #305152  #5005152    # desired frame length for all of the audio samples.\n",
        "frame_length = 2048\n",
        "hop_length = 512\n",
        "\n",
        "# folder_path = '/content/drive/MyDrive/Colab_Notebooks/AudioFiles/TESS' \n",
        "folder_path = '/content/drive/MyDrive/Colab_Notebooks/AudioFiles/Used Dataset'\n",
        "\n",
        "for subdir, dirs, files in os.walk(folder_path):\n",
        "  for file in files: \n",
        "    # Fetch the sample rate.\n",
        "      _, sr = librosa.load(path = os.path.join(subdir,file), sr = None) # sr (the sample rate) is used for librosa's MFCCs. '_' is irrelevant.\n",
        "    # Load the audio file.\n",
        "      rawsound = AudioSegment.from_file(os.path.join(subdir,file)) \n",
        "    # Normalize the audio to +5.0 dBFS.\n",
        "      normalizedsound = effects.normalize(rawsound, headroom = 5.0) \n",
        "    # Transform the normalized audio to np.array of samples.\n",
        "      normal_x = np.array(normalizedsound.get_array_of_samples(), dtype = 'float32')\n",
        "    # Trim silence from the beginning and the end.\n",
        "      xt,  index = librosa.effects.trim(normal_x, top_db=30)\n",
        "    # Pad for duration equalization. \n",
        "      padded_x = np.pad(xt, (0, total_length-len(xt)), 'constant')\n",
        "    # Noise reduction.\n",
        "      final_x = nr.reduce_noise(y=padded_x,y_noise=padded_x, sr=sr)\n",
        "\n",
        "   # Features extraction \n",
        "      f1 = librosa.feature.rms(final_x, frame_length=frame_length, hop_length=hop_length) # Energy - Root Mean Square   \n",
        "      f2 = librosa.feature.zero_crossing_rate(final_x , frame_length=frame_length, hop_length=hop_length, center=True) # ZCR      \n",
        "      f3 = librosa.feature.mfcc(final_x, sr=sr, n_mfcc=13, hop_length = hop_length) # MFCC\n",
        "      f4 = librosa.feature.chroma_stft(final_x,sr=sr) #chroma\n",
        "      \n",
        "   # Emotion extraction from the different databases\n",
        "      if (find_emotion_T(file) != \"-1\"): #TESS database validation\n",
        "            name = find_emotion_T(file)\n",
        "            \n",
        "      else:                              #RAVDESS database validation\n",
        "            name = file[6:8]\n",
        "                                \n",
        "\n",
        "   # Filling the data lists  \n",
        "      rms.append(f1)\n",
        "      zcr.append(f2)\n",
        "      mfcc.append(f3)\n",
        "      chroma.append(f4)\n",
        "      emotions.append(emotionfix(name)) \n",
        "      \n",
        "\n",
        "toc = time.perf_counter()\n",
        "print(f\"Running time: {(toc - tic)/60:0.4f} minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DFP_FOZsp6qO"
      },
      "outputs": [],
      "source": [
        "# Adjusting features shape to the 3D format: (batch, timesteps, feature)\n",
        "\n",
        "f_rms = np.asarray(rms).astype('float32')\n",
        "f_rms = np.swapaxes(f_rms,1,2)\n",
        "f_zcr = np.asarray(zcr).astype('float32')\n",
        "f_zcr = np.swapaxes(f_zcr,1,2)\n",
        "f_mfccs = np.asarray(mfcc).astype('float32')\n",
        "f_mfccs = np.swapaxes(f_mfccs,1,2)\n",
        "f_chroma = np.asarray(chroma).astype('float32')\n",
        "f_chroma = np.swapaxes(f_chroma,1,2)\n",
        "\n",
        "print('RMS shape:',f_rms.shape)\n",
        "print('ZCR shape:',f_zcr.shape)\n",
        "print('MFCCs shape:',f_mfccs.shape)\n",
        "print('Chroma shape:',f_chroma.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wSpXqgJqMHvR"
      },
      "outputs": [],
      "source": [
        "# Concatenating all features to 'X' variable.\n",
        "X = np.concatenate(( f_rms,f_zcr,f_mfccs,  f_chroma), axis=2) #,\n",
        "# Preparing 'Y' as a 2D shaped variable.\n",
        "Y = np.asarray(emotions).astype('int8')\n",
        "Y = np.expand_dims(Y, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JZR2SoDp61pR"
      },
      "outputs": [],
      "source": [
        "# Save X,Y arrays as lists to json files.\n",
        "\n",
        "x_data = X.tolist() \n",
        "x_path = '/content/drive/My Drive/Colab_Notebooks/X_datanew.json' # FILE SAVE PATH\n",
        "dump(obj = x_data, fp = x_path)\n",
        "\n",
        "y_data = Y.tolist() \n",
        "y_path = '/content/drive/My Drive/Colab_Notebooks/Y_datanew.json' # FILE SAVE PATH\n",
        "dump(obj = y_data, fp = y_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oy53CmsODtSQ"
      },
      "outputs": [],
      "source": [
        "# Load X,Y json files back into lists, convert to np.arrays\n",
        "\n",
        "x_path = '/content/drive/My Drive/Colab_Notebooks/X_datanew.json' # FILE LOAD PATH\n",
        "X = load(x_path)\n",
        "X = np.asarray(X, dtype = 'float32')\n",
        "\n",
        "y_path = '/content/drive/My Drive/Colab_Notebooks/Y_datanew.json' # FILE LOAD PATH\n",
        "Y = load(y_path)\n",
        "Y = np.asarray(Y, dtype = 'int8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "h1Photkwq-bw"
      },
      "outputs": [],
      "source": [
        "# Split to train, validation, and test sets.\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_tosplit, y_train, y_tosplit = train_test_split(X, Y, test_size = 0.125, random_state = 1)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_tosplit, y_tosplit, test_size = 0.304, random_state = 1)\n",
        "\n",
        "#'One-hot' vectors for Y: emotion \n",
        "\n",
        "y_train_class = tf.keras.utils.to_categorical(y_train, 7, dtype = 'int8')\n",
        "y_val_class = tf.keras.utils.to_categorical(y_val, 7, dtype = 'int8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NgRlZBJbMHvX"
      },
      "outputs": [],
      "source": [
        "# x_train, x_val, and x_test shape check.\n",
        "print(np.shape(x_train))\n",
        "print(np.shape(x_val))\n",
        "print(np.shape(x_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aW4qJ9VogZJ2"
      },
      "outputs": [],
      "source": [
        "# Save x_test, y_test to JSON.\n",
        "\n",
        "file_path = 'x_test_data.json'\n",
        "dump(obj = x_test, fp = file_path)\n",
        "\n",
        "file_path = 'y_test_data.json'\n",
        "dump(obj = y_test, fp = file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1ROkmISHZCkM"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras import callbacks "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3DroQ71fXxPN"
      },
      "outputs": [],
      "source": [
        "# Initializing the model\n",
        "\n",
        "model = Sequential() #relu , siqmoid , software\n",
        "model.add(layers.LSTM(64, return_sequences = True, input_shape=(X.shape[1:3])))\n",
        "model.add(layers.LSTM(64))\n",
        "model.add(layers.Dense(7, activation = 'relu'))\n",
        "\n",
        "\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "batch_size = 23\n",
        "\n",
        "# Callbacks functions\n",
        "checkpoint_path = '/content/drive/My Drive/Colab_Notebooks/best_weights.hdf5'\n",
        "model.load_weights(checkpoint_path)\n",
        "\n",
        "\n",
        "#-> Save the best weights\n",
        "mcp_save = callbacks.ModelCheckpoint(checkpoint_path, save_best_only=True,\n",
        "                           monitor='val_categorical_accuracy',\n",
        "                           mode='max')\n",
        "#-> Reduce learning rate after 100 epoches without improvement.\n",
        "rlrop = callbacks.ReduceLROnPlateau(monitor='val_categorical_accuracy', \n",
        "                                    factor=0.1, patience=100)\n",
        "                             \n",
        "# Compile & train   \n",
        "model.compile(loss='categorical_crossentropy', \n",
        "                optimizer='RMSProp', \n",
        "                metrics=['categorical_accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train_class, #shuffle= True, btsh2lb al data\n",
        "                      epochs=340, batch_size = batch_size,   #340   \n",
        "                      validation_data = (x_val, y_val_class), \n",
        "                      callbacks = [mcp_save, rlrop])\n",
        "# Define the best weights to the model.\n",
        "model.load_weights(checkpoint_path)\n",
        "\n",
        "print(f\"Running time: {(toc - tic)/60:0.4f} minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lrq5r7wpufzS"
      },
      "outputs": [],
      "source": [
        "# checkpoint_path = '/content/drive/My Drive/Colab_Notebooks/best_weights.hdf5'\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(layers.LSTM(64, return_sequences = True, input_shape=(X.shape[1:3])))\n",
        "# model.add(layers.LSTM(64))\n",
        "# model.add(layers.Dense(7, activation = 'softmax'))\n",
        "\n",
        "# model.compile(loss='categorical_crossentropy', \n",
        "#                 optimizer='RMSProp', \n",
        "#                 metrics=['categorical_accuracy'])\n",
        "\n",
        "\n",
        "# model.load_weights(checkpoint_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "t3xnV1S7ra_Y"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nu3eLmdtNlCF"
      },
      "outputs": [],
      "source": [
        "# Loss, Accuracy presentation\n",
        "\n",
        "# Plot history: Loss\n",
        "plt.plot(history.history['loss'], label='Loss (training data)')\n",
        "plt.plot(history.history['val_loss'], label='Loss (validation data)')\n",
        "plt.title('Loss for train and validation')\n",
        "plt.ylabel('Loss value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()\n",
        "\n",
        "#Plot history: Accuracy\n",
        "plt.plot(history.history['categorical_accuracy'], label='Acc (training data)')\n",
        "plt.plot(history.history['val_categorical_accuracy'], label='Acc (validation data)')\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Acc %')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Bc6qcBGOMHv7"
      },
      "outputs": [],
      "source": [
        "# Validation score\n",
        "loss,acc = model.evaluate(x_val, y_val_class, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XhR-4z86VPCy"
      },
      "outputs": [],
      "source": [
        "y_val_class.shape\n",
        "x_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3Icd1yFHra_Z"
      },
      "outputs": [],
      "source": [
        "# Validation Confusion matrix\n",
        "\n",
        "y_val_class = np.argmax(y_val_class, axis=1)\n",
        "predictions = model.predict(x_val)\n",
        "y_pred_class = np.argmax(predictions, axis=1)\n",
        "cm=confusion_matrix(y_val_class, y_pred_class)\n",
        "\n",
        "# index = ['neutral', 'calm', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']  \n",
        "# columns = ['neutral', 'calm', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']  \n",
        "\n",
        "index = ['neutral', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']  \n",
        "columns = ['neutral', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']  \n",
        "\n",
        "cm_df = pd.DataFrame(cm,index,columns)\n",
        "plt.figure(figsize=(12,7))\n",
        "ax = plt.axes()\n",
        "\n",
        "sns.heatmap(cm_df, ax = ax, cmap = 'PuBu', fmt=\"d\", annot=True) \n",
        "ax.set_ylabel('True emotion')\n",
        "ax.set_xlabel('Predicted emotion')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "j70DNePpra_c"
      },
      "outputs": [],
      "source": [
        "# Validation set prediction accuracy rates\n",
        "\n",
        "values = cm.diagonal()\n",
        "print(values) \n",
        "row_sum = np.sum(cm,axis=1)\n",
        "print(row_sum)\n",
        "acc = values / row_sum\n",
        "\n",
        "print('Validation set predicted emotions accuracy:')\n",
        "for e in range(0, len(values)):\n",
        "    print(index[e],':', f\"{(acc[e]):0.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8ybMruIrra_d"
      },
      "outputs": [],
      "source": [
        "# Saving model & weights\n",
        "\n",
        "from keras.models import model_from_json\n",
        "from keras.models import load_model\n",
        "\n",
        "model_json = model.to_json()\n",
        "saved_model_path = '/content/drive/My Drive/Colab_Notebooks/model8723.json'\n",
        "saved_weights_path = '/content/drive/My Drive/Colab_Notebooks/model8723_weights.h5'\n",
        "\n",
        "\n",
        "with open(saved_model_path, \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "    \n",
        "model.save_weights(saved_weights_path)\n",
        "print(\"Saved model to disk\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7CvsDF6cOa3z"
      },
      "outputs": [],
      "source": [
        "# Reading the model from JSON file\n",
        "\n",
        "saved_model_path = '/content/drive/MyDrive/Colab_Notebooks/model8723.json'\n",
        "saved_weights_path = '/content/drive/MyDrive/Colab_Notebooks/model8723_weights.h5'\n",
        "\n",
        "with open(saved_model_path , 'r') as json_file:\n",
        "    json_savedModel = json_file.read()\n",
        "    \n",
        "# Loading the model architecture, weights\n",
        "model = tf.keras.models.model_from_json(json_savedModel)\n",
        "model.load_weights(saved_weights_path)\n",
        "\n",
        "# Compiling the model with similar parameters as the original model.\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "                optimizer='RMSProp', \n",
        "                metrics=['categorical_accuracy'])\n",
        "\n",
        "# Model's structure visualization\n",
        "tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9aw0_8VfOa30"
      },
      "outputs": [],
      "source": [
        "# Loading x_test, y_test json files, and converting to np.arrays\n",
        "\n",
        "x_test = load( 'x_test_data.json')\n",
        "x_test = np.asarray(x_test).astype('float32')\n",
        "\n",
        "y_test = load('y_test_data.json')\n",
        "y_test = np.asarray(y_test).astype('int8')\n",
        "\n",
        "y_test_class = tf.keras.utils.to_categorical(y_test, 7, dtype = 'int8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "b56-z_GUOa31"
      },
      "outputs": [],
      "source": [
        "loss, acc = model.evaluate(x_test, y_test_class, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9ssa4HRVOa31"
      },
      "outputs": [],
      "source": [
        "# Test set Confusion matrix\n",
        "print(x_test.shape)\n",
        "y = np.argmax(y_test_class, axis=1)\n",
        "predictions = model.predict(x_test)\n",
        "y_pred_class = np.argmax(predictions, axis=1)\n",
        "\n",
        "cm=confusion_matrix(y, y_pred_class)\n",
        "\n",
        "# index = ['neutral', 'calm', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']  \n",
        "# columns = ['neutral', 'calm', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']  \n",
        "\n",
        "index = ['neutral', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']  \n",
        "columns = ['neutral', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']  \n",
        "\n",
        " \n",
        "cm_df = pd.DataFrame(cm,index,columns)                      \n",
        "plt.figure(figsize=(12,7))\n",
        "ax = plt.axes()\n",
        "\n",
        "sns.heatmap(cm_df, ax = ax, cmap = 'BuGn', fmt=\"d\", annot=True)\n",
        "ax.set_ylabel('True emotion')\n",
        "ax.set_xlabel('Predicted emotion')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Hwbkmv2yOa32"
      },
      "outputs": [],
      "source": [
        "  # Test set prediction accuracy rates\n",
        "\n",
        "values = cm.diagonal()\n",
        "row_sum = np.sum(cm,axis=1)\n",
        "acc = values / row_sum\n",
        "\n",
        "print('Test set predicted emotions accuracy:')\n",
        "for e in range(0, len(values)):\n",
        "    print(index[e],':', f\"{(acc[e]):0.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DmHZYHVErkQ2"
      },
      "outputs": [],
      "source": [
        "subdir = '/content/drive/MyDrive/Colab_Notebooks/AudioFiles/Used Dataset'\n",
        "traning = [\"03-01-07-02-01-01-23.wav\", \"1013_TSI_SAD_XX.wav\", \"YAF_young_happy.wav\"]\n",
        "\n",
        "# subdir = \"/content/drive/MyDrive/Colab_Notebooks/AudioFiles\"\n",
        "# traning = [\"ode.wav\"]\n",
        "\n",
        "for file in traning:\n",
        "    rms = []\n",
        "    zcr = []\n",
        "    mfcc = []\n",
        "    chroma = []\n",
        "    # emotions = []\n",
        "\n",
        "    # Initialize variables\n",
        "    total_length = 228864 #228864  #305152  #5005152    # desired frame length for all of the audio samples.\n",
        "    frame_length = 2048\n",
        "    hop_length = 512\n",
        "\n",
        "\n",
        "    # Fetch the sample rate.\n",
        "    _, sr = librosa.load(path = os.path.join(subdir,file), sr = None) # sr (the sample rate) is used for librosa's MFCCs. '_' is irrelevant.\n",
        "    # Load the audio file.\n",
        "    rawsound = AudioSegment.from_file(os.path.join(subdir,file)) \n",
        "    # Normalize the audio to +5.0 dBFS.\n",
        "    normalizedsound = effects.normalize(rawsound, headroom = 5.0) \n",
        "    # Transform the normalized audio to np.array of samples.\n",
        "    normal_x = np.array(normalizedsound.get_array_of_samples(), dtype = 'float32')\n",
        "    # Trim silence from the beginning and the end.\n",
        "    xt,  index = librosa.effects.trim(normal_x, top_db=30)\n",
        "    # Pad for duration equalization.\n",
        "    # print(xt.shape)\n",
        "    padded_x = np.pad(xt, (0, total_length-len(xt)), 'constant')\n",
        "    # Noise reduction.\n",
        "    final_x = nr.reduce_noise(y=padded_x,y_noise=padded_x, sr=sr)\n",
        "\n",
        "    # Features extraction \n",
        "    f1 = librosa.feature.rms(final_x, frame_length=frame_length, hop_length=hop_length) # Energy - Root Mean Square\n",
        "    f2 = librosa.feature.zero_crossing_rate(final_x , frame_length=frame_length, hop_length=hop_length, center=True) # ZCR\n",
        "    f3 = librosa.feature.mfcc(final_x, sr=sr, n_mfcc=13, hop_length = hop_length) # MFCC\n",
        "    f4 = librosa.feature.chroma_stft(final_x,sr=sr) #chroma\n",
        "      \n",
        "\n",
        "    # Emotion extraction from the different databases\n",
        "    # if (find_emotion_T(file) != \"-1\"): #TESS database validation\n",
        "    #       name = find_emotion_T(file)\n",
        "    # else:                              #RAVDESS database validation\n",
        "    #       name = file[6:8]                      \n",
        "    # print(name);\n",
        "    # Filling the data lists  \n",
        "    rms.append(f1)\n",
        "    zcr.append(f2)\n",
        "    mfcc.append(f3)\n",
        "    chroma.append(f4)\n",
        "    # emotions.append((name)) \n",
        "\n",
        "    # Adjusting features shape to the 3D format: (batch, timesteps, feature)\n",
        "\n",
        "    f_rms = np.asarray(rms).astype('float32')\n",
        "    f_rms = np.swapaxes(f_rms,1,2)\n",
        "    f_zcr = np.asarray(zcr).astype('float32')\n",
        "    f_zcr = np.swapaxes(f_zcr,1,2)\n",
        "    f_mfccs = np.asarray(mfcc).astype('float32')\n",
        "    f_mfccs = np.swapaxes(f_mfccs,1,2)\n",
        "    f_chroma = np.asarray(chroma).astype('float32')\n",
        "    f_chroma = np.swapaxes(f_chroma,1,2)\n",
        "\n",
        "    # Concatenating all features to 'X' variable.\n",
        "    X = np.concatenate(( f_rms,f_zcr,f_mfccs,  f_chroma), axis=2) #,\n",
        "\n",
        "    # Preparing 'Y' as a 2D shaped variable.\n",
        "    # Y = np.asarray(emotions).astype('int8')\n",
        "    # Y = np.expand_dims(Y, axis=1)\n",
        "\n",
        "\n",
        "    # y = np.argmax(Y, axis=1)\n",
        "    predictions = model.predict(X)\n",
        "    # y_pred_class = np.argmax(predictions, axis=1)\n",
        "\n",
        "    emotions = {\n",
        "        0 : 'neutral',\n",
        "        1 : 'happy',\n",
        "        2 : 'sad',\n",
        "        3 : 'angry',\n",
        "        4 : 'fearful',  \n",
        "        5 : 'disgust',\n",
        "        6 : 'suprised'   \n",
        "    }  \n",
        "    # emo_list = list(emotions.values())\n",
        "\n",
        "    max_emo = np.argmax(predictions)\n",
        "    print('max emotion:', emotions.get(max_emo,-1))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "GD 2_model.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}