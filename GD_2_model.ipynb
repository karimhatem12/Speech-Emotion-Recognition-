{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karimhatem12/Speech-Emotion-Recognition-/blob/main/GD_2_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JspCH3lVUuUG"
      },
      "source": [
        "# **Speech Emotion Recogition (Classification) in real-time using Deep LSTM layers**\n",
        "### ***A Deep Learning LSTM based model with keras.***\n",
        "---\n",
        "\n",
        "### Final project (B.Sc. requirement)  \n",
        "Development by **Karim hatem hamed.**\n",
        "\n",
        "Instructor: **Dr. Eslam Elshaarawy**\n",
        "\n",
        "Computer Science.\n",
        "\n",
        "MSA Universty , Egypt.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4RcjQMCV89B"
      },
      "source": [
        "# **LIBRARIES & GOOGLE AUTH**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nYS9qahzAQ_",
        "outputId": "38619b8a-bd4c-415c-fa31-3f42d2a56bf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K31C-zTfZdFa"
      },
      "outputs": [],
      "source": [
        " %%capture\n",
        "!pip install pydub\n",
        "!pip install pywt\n",
        "!pip install noisereduce\n",
        "!pip install json-tricks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "li2EfZXmQehM"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "from json_tricks import dump, load\n",
        "\n",
        "from pydub import AudioSegment, effects\n",
        "import librosa\n",
        "import noisereduce as nr\n",
        "import pywt\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUMWt35lTQQL"
      },
      "outputs": [],
      "source": [
        "# Emotion kind validation function for TESS database, due to emotions written within the file names.\n",
        "def find_emotion_T(name): \n",
        "        if('neutral' in name): return \"01\"\n",
        "        elif('NEU' in name): return \"01\"\n",
        "        elif('happy' in name): return \"03\"\n",
        "        elif('HAP' in name): return \"03\"\n",
        "        elif('sad' in name): return \"04\"\n",
        "        elif('SAD' in name): return \"04\"\n",
        "        elif('angry' in name): return \"05\"\n",
        "        elif('ANG' in name): return \"05\"\n",
        "        elif('fear' in name): return \"06\"\n",
        "        elif('FEA' in name): return \"06\"\n",
        "        elif('disgust' in name): return \"07\"\n",
        "        elif('DIS' in name): return \"07\"\n",
        "        elif('ps' in name): return \"08\"\n",
        "        else: return \"-1\"\n",
        "        \n",
        " \n",
        "# 'emotions' list fix for classification purposes:\n",
        "#     Classification values start from 0, Thus an 'n = n-1' operation has been executed for both RAVDESS and TESS databases:\n",
        "def emotionfix(e_num):\n",
        "        if e_num == \"01\":   return 0 # neutral\n",
        "        #elif e_num == \"02\": return 1 # calm\n",
        "        elif e_num == \"03\": return 1 # happy\n",
        "        elif e_num == \"04\": return 2 # sad\n",
        "        elif e_num == \"05\": return 3 # angry\n",
        "        elif e_num == \"06\": return 4 # fear\n",
        "        elif e_num == \"07\": return 5 # disgust\n",
        "        else:               return 6 # suprised"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydC8v5SNra-0",
        "outputId": "76de6534-db33-4524-c400-0bf32dfbd1a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum sample length: 204288\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Maximum samples count for padding purposes.\n",
        "\n",
        "sample_lengths = []\n",
        "# folder_path = '/content/drive/MyDrive/Colab_Notebooks/AudioFiles/TESS'\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/Colab_Notebooks/AudioFiles/Used Dataset'\n",
        "\n",
        "for subdir, dirs, files in os.walk(folder_path):\n",
        "  for file in files: \n",
        "    x, sr = librosa.load(path = os.path.join(subdir,file), sr = None)\n",
        "    xt, index = librosa.effects.trim(x, top_db=30)\n",
        "     \n",
        "    sample_lengths.append(len(xt))\n",
        "\n",
        "print('Maximum sample length:', np.max(sample_lengths))               \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WHsU4Noi1n_q",
        "outputId": "d39cf8b7-f5cd-40bf-a234-bd0ac57278d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running time: 17.1785 minutes\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "tic = time.perf_counter()\n",
        "\n",
        "# Initialize data lists\n",
        "rms = []\n",
        "zcr = []\n",
        "mfcc = []\n",
        "chroma = []\n",
        "emotions = []\n",
        "\n",
        "# Initialize variables\n",
        "total_length = 228864 #228864  #305152  #5005152    # desired frame length for all of the audio samples.\n",
        "frame_length = 2048\n",
        "hop_length = 512\n",
        "\n",
        "# folder_path = '/content/drive/MyDrive/Colab_Notebooks/AudioFiles/TESS' \n",
        "folder_path = '/content/drive/MyDrive/Colab_Notebooks/AudioFiles/Used Dataset'\n",
        "\n",
        "for subdir, dirs, files in os.walk(folder_path):\n",
        "  for file in files: \n",
        "    # Fetch the sample rate.\n",
        "      _, sr = librosa.load(path = os.path.join(subdir,file), sr = None) # sr (the sample rate) is used for librosa's MFCCs. '_' is irrelevant.\n",
        "    # Load the audio file.\n",
        "      rawsound = AudioSegment.from_file(os.path.join(subdir,file)) \n",
        "    # Normalize the audio to +5.0 dBFS.\n",
        "      normalizedsound = effects.normalize(rawsound, headroom = 5.0) \n",
        "    # Transform the normalized audio to np.array of samples.\n",
        "      normal_x = np.array(normalizedsound.get_array_of_samples(), dtype = 'float32')\n",
        "    # Trim silence from the beginning and the end.\n",
        "      xt,  index = librosa.effects.trim(normal_x, top_db=30)\n",
        "    # Pad for duration equalization. \n",
        "      padded_x = np.pad(xt, (0, total_length-len(xt)), 'constant')\n",
        "    # Noise reduction.\n",
        "      final_x = nr.reduce_noise(y=padded_x,y_noise=padded_x, sr=sr)\n",
        "\n",
        "   # Features extraction \n",
        "      f1 = librosa.feature.rms(final_x, frame_length=frame_length, hop_length=hop_length) # Energy - Root Mean Square   \n",
        "      f2 = librosa.feature.zero_crossing_rate(final_x , frame_length=frame_length, hop_length=hop_length, center=True) # ZCR      \n",
        "      f3 = librosa.feature.mfcc(final_x, sr=sr, n_mfcc=13, hop_length = hop_length) # MFCC\n",
        "      f4 = librosa.feature.chroma_stft(final_x,sr=sr) #chroma\n",
        "      \n",
        "   # Emotion extraction from the different databases\n",
        "      if (find_emotion_T(file) != \"-1\"): #TESS database validation\n",
        "            name = find_emotion_T(file)\n",
        "            \n",
        "      else:                              #RAVDESS database validation\n",
        "            name = file[6:8]\n",
        "                                \n",
        "\n",
        "   # Filling the data lists  \n",
        "      rms.append(f1)\n",
        "      zcr.append(f2)\n",
        "      mfcc.append(f3)\n",
        "      chroma.append(f4)\n",
        "      emotions.append(emotionfix(name)) \n",
        "      \n",
        "\n",
        "toc = time.perf_counter()\n",
        "print(f\"Running time: {(toc - tic)/60:0.4f} minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DFP_FOZsp6qO",
        "outputId": "8809166a-6625-4672-fc79-7a1985aa5f84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMS shape: (4996, 448, 1)\n",
            "ZCR shape: (4996, 448, 1)\n",
            "MFCCs shape: (4996, 448, 13)\n",
            "Chroma shape: (4996, 448, 12)\n"
          ]
        }
      ],
      "source": [
        "# Adjusting features shape to the 3D format: (batch, timesteps, feature)\n",
        "\n",
        "f_rms = np.asarray(rms).astype('float32')\n",
        "f_rms = np.swapaxes(f_rms,1,2)\n",
        "f_zcr = np.asarray(zcr).astype('float32')\n",
        "f_zcr = np.swapaxes(f_zcr,1,2)\n",
        "f_mfccs = np.asarray(mfcc).astype('float32')\n",
        "f_mfccs = np.swapaxes(f_mfccs,1,2)\n",
        "f_chroma = np.asarray(chroma).astype('float32')\n",
        "f_chroma = np.swapaxes(f_chroma,1,2)\n",
        "\n",
        "print('RMS shape:',f_rms.shape)\n",
        "print('ZCR shape:',f_zcr.shape)\n",
        "print('MFCCs shape:',f_mfccs.shape)\n",
        "print('Chroma shape:',f_chroma.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wSpXqgJqMHvR"
      },
      "outputs": [],
      "source": [
        "# Concatenating all features to 'X' variable.\n",
        "X = np.concatenate(( f_rms,f_zcr,f_mfccs,  f_chroma), axis=2) #,\n",
        "# Preparing 'Y' as a 2D shaped variable.\n",
        "Y = np.asarray(emotions).astype('int8')\n",
        "Y = np.expand_dims(Y, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JZR2SoDp61pR",
        "outputId": "9b7409e4-a602-4857-b0c7-b10e0ada6474"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[[6], [4], [2], [4], [1], [6], [2], [6], [1], [5], [4], [1], [4], [0], [3], [5], [3], [1], [0], [6], [6], [4], [3], [5], [2], [5], [3], [0], [2], [4], [6], [5], [1], [2], [3], [4], [0], [2], [1], [6], [0], [2], [6], [1], [4], [0], [1], [3], [5], [4], [5], [3], [5], [0], [4], [5], [3], [1], [6], [3], [2], [6], [2], [0], [4], [1], [1], [0], [5], [3], [6], [0], [4], [2], [6], [3], [2], [4], [5], [3], [4], [5], [0], [6], [2], [1], [4], [6], [3], [2], [0], [3], [6], [5], [1], [0], [2], [1], [4], [5], [3], [0], [6], [2], [0], [1], [1], [4], [5], [2], [0], [5], [3], [4], [5], [6], [1], [3], [6], [2], [4], [2], [6], [6], [0], [3], [4], [1], [0], [3], [5], [2], [1], [5], [6], [0], [1], [4], [2], [5], [1], [4], [3], [0], [6], [5], [2], [1], [4], [5], [2], [3], [6], [3], [4], [0], [1], [5], [6], [0], [4], [5], [2], [3], [2], [0], [6], [1], [3], [1], [6], [1], [6], [0], [4], [5], [3], [2], [0], [4], [1], [0], [5], [1], [5], [3], [3], [6], [4], [4], [2], [2], [3], [5], [4], [0], [2], [6], [6], [2], [3], [1], [5], [0], [5], [2], [3], [6], [6], [0], [1], [4], [2], [0], [4], [1], [4], [3], [5], [1], [3], [2], [1], [6], [5], [4], [0], [1], [5], [5], [4], [6], [3], [2], [6], [0], [3], [0], [2], [4], [2], [0], [3], [2], [4], [5], [6], [0], [1], [1], [6], [3], [1], [4], [5], [0], [2], [4], [1], [6], [5], [3], [0], [5], [3], [0], [6], [6], [1], [5], [2], [4], [2], [3], [2], [1], [3], [5], [0], [0], [4], [6], [4], [6], [1], [4], [1], [1], [5], [4], [3], [5], [3], [6], [0], [2], [2], [0], [5], [3], [0], [6], [4], [3], [5], [6], [1], [2], [2], [4], [2], [3], [4], [1], [0], [0], [5], [2], [6], [1], [6], [3], [5], [0], [1], [5], [4], [1], [6], [3], [0], [2], [4], [5], [3], [4], [6], [1], [5], [3], [0], [2], [2], [6], [0], [1], [2], [2], [6], [0], [3], [1], [6], [5], [4], [4], [3], [4], [1], [5], [3], [5], [4], [0], [6], [2], [1], [3], [0], [6], [3], [5], [1], [0], [2], [2], [6], [4], [6], [4], [4], [1], [2], [3], [1], [0], [0], [5], [5], [2], [3], [6], [6], [2], [3], [5], [0], [1], [5], [4], [4], [3], [6], [0], [0], [5], [1], [1], [2], [2], [6], [4], [4], [3], [3], [6], [0], [2], [4], [1], [5], [1], [5], [5], [3], [2], [3], [1], [0], [2], [4], [6], [0], [5], [6], [0], [1], [4], [0], [1], [6], [3], [6], [2], [5], [4], [6], [2], [5], [3], [5], [0], [3], [2], [4], [1], [4], [1], [6], [2], [3], [1], [2], [4], [5], [3], [0], [6], [0], [3], [5], [0], [0], [2], [4], [4], [1], [6], [1], [5], [0], [4], [5], [6], [2], [2], [1], [3], [5], [6], [3], [3], [6], [1], [6], [4], [1], [5], [0], [2], [0], [4], [3], [2], [2], [5], [4], [1], [6], [3], [5], [4], [1], [0], [3], [1], [5], [0], [0], [3], [6], [2], [5], [2], [4], [6], [1], [0], [4], [5], [6], [3], [1], [4], [0], [2], [5], [1], [5], [6], [0], [3], [3], [6], [4], [4], [2], [2], [4], [1], [2], [3], [6], [1], [6], [0], [5], [0], [2], [1], [2], [6], [5], [4], [5], [3], [0], [3], [4], [1], [0], [5], [3], [2], [5], [2], [1], [6], [6], [3], [0], [4], [1], [4], [2], [0], [4], [3], [1], [0], [5], [2], [6], [6], [4], [0], [1], [4], [5], [3], [2], [5], [3], [6], [1], [0], [6], [4], [1], [3], [5], [2], [0], [3], [6], [5], [2], [1], [6], [4], [0], [6], [1], [5], [4], [2], [3], [0], [0], [2], [3], [2], [6], [4], [5], [3], [1], [1], [5], [4], [3], [2], [1], [3], [2], [5], [5], [6], [4], [0], [0], [6], [4], [4], [5], [2], [2], [0], [6], [1], [3], [0], [6], [1], [1], [3], [4], [4], [0], [1], [5], [6], [5], [3], [2], [0], [6], [5], [3], [2], [6], [4], [0], [5], [2], [3], [1], [0], [1], [3], [1], [2], [0], [6], [5], [4], [2], [4], [6], [3], [2], [1], [3], [5], [5], [0], [4], [1], [4], [6], [0], [5], [4], [5], [6], [3], [2], [6], [1], [2], [4], [3], [0], [2], [4], [0], [0], [6], [5], [1], [6], [1], [2], [3], [5], [6], [5], [0], [0], [1], [2], [1], [4], [3], [4], [3], [5], [4], [3], [4], [6], [5], [1], [6], [0], [2], [3], [2], [2], [3], [6], [6], [0], [4], [1], [0], [3], [1], [2], [5], [3], [1], [1], [5], [6], [4], [4], [0], [2], [5], [0], [6], [1], [0], [2], [2], [3], [3], [5], [5], [6], [4], [3], [4], [4], [2], [2], [6], [0], [3], [6], [0], [1], [1], [5], [4], [3], [5], [5], [0], [2], [6], [1], [0], [1], [4], [6], [5], [2], [5], [4], [2], [3], [0], [4], [3], [6], [1], [1], [1], [5], [3], [2], [2], [0], [3], [4], [5], [6], [0], [6], [0], [6], [2], [4], [4], [5], [3], [0], [1], [6], [1], [4], [0], [2], [3], [2], [4], [1], [6], [5], [3], [5], [5], [3], [0], [6], [3], [0], [6], [1], [2], [1], [2], [4], [0], [6], [4], [3], [4], [0], [5], [1], [5], [2], [6], [1], [6], [1], [4], [2], [2], [0], [5], [3], [5], [3], [4], [1], [6], [2], [1], [0], [3], [4], [6], [2], [0], [5], [3], [3], [5], [4], [1], [1], [2], [4], [0], [5], [6], [0], [4], [1], [2], [5], [0], [5], [3], [6], [3], [2], [6], [6], [1], [4], [5], [6], [0], [2], [4], [2], [3], [3], [0], [1], [6], [1], [6], [4], [0], [2], [1], [5], [4], [5], [3], [0], [2], [4], [3], [4], [0], [6], [1], [1], [5], [3], [2], [5], [1], [0], [2], [4], [0], [6], [3], [6], [5], [3], [2], [2], [6], [4], [5], [4], [3], [6], [0], [1], [0], [5], [1], [0], [3], [4], [5], [2], [6], [1], [2], [5], [0], [1], [5], [0], [2], [3], [4], [2], [1], [3], [5], [4], [6], [3], [1], [6], [0], [2], [0], [5], [6], [1], [2], [4], [0], [1], [4], [6], [3], [4], [3], [1], [2], [5], [0], [5], [5], [3], [0], [6], [3], [5], [6], [4], [2], [1], [2], [4], [0], [3], [6], [0], [6], [1], [2], [2], [4], [5], [1], [0], [3], [1], [0], [6], [3], [2], [5], [1], [4], [4], [5], [2], [0], [6], [5], [3], [1], [6], [4], [3], [2], [5], [6], [5], [4], [1], [2], [6], [0], [4], [3], [0], [1], [1], [2], [2], [6], [4], [3], [5], [1], [5], [0], [3], [4], [5], [0], [0], [4], [2], [6], [2], [3], [1], [6], [3], [5], [0], [6], [4], [6], [3], [0], [1], [4], [1], [2], [5], [2], [1], [0], [5], [1], [6], [0], [5], [4], [3], [3], [4], [2], [1], [5], [4], [3], [1], [2], [5], [4], [0], [2], [6], [6], [3], [3], [6], [2], [0], [3], [1], [0], [5], [2], [4], [6], [2], [6], [5], [5], [0], [3], [1], [0], [4], [1], [4], [3], [1], [5], [2], [6], [3], [4], [5], [0], [6], [4], [2], [0], [3], [6], [2], [1], [0], [3], [1], [5], [4], [6], [2], [5], [1], [3], [4], [2], [1], [6], [0], [0], [4], [5], [3], [6], [2], [6], [0], [5], [1], [4], [3], [5], [4], [2], [2], [2], [0], [1], [1], [0], [3], [5], [6], [4], [6], [6], [4], [4], [0], [3], [0], [5], [1], [5], [6], [3], [1], [2], [5], [6], [4], [3], [0], [5], [2], [1], [2], [4], [3], [4], [0], [2], [1], [2], [1], [0], [5], [6], [6], [3], [6], [5], [4], [3], [4], [1], [2], [0], [5], [3], [0], [1], [2], [6], [5], [6], [3], [4], [1], [0], [2], [5], [4], [3], [1], [0], [3], [6], [3], [6], [2], [4], [2], [0], [5], [1], [5], [4], [5], [6], [1], [2], [6], [3], [1], [4], [0], [0], [4], [2], [0], [3], [6], [1], [4], [1], [5], [2], [3], [5], [5], [0], [2], [6], [1], [6], [4], [3], [0], [5], [2], [3], [2], [6], [0], [5], [2], [3], [0], [6], [4], [1], [4], [1], [5], [4], [1], [3], [1], [2], [0], [0], [6], [3], [5], [4], [4], [3], [0], [6], [2], [2], [5], [5], [3], [6], [1], [6], [3], [0], [0], [4], [1], [5], [2], [4], [6], [2], [1], [4], [5], [1], [0], [6], [5], [2], [4], [1], [3], [3], [0], [0], [2], [3], [6], [6], [4], [1], [3], [5], [5], [2], [1], [2], [4], [6], [1], [3], [5], [2], [0], [6], [0], [4], [1], [4], [3], [4], [5], [2], [3], [1], [0], [5], [6], [2], [5], [1], [0], [3], [5], [2], [4], [6], [3], [0], [6], [5], [1], [4], [3], [1], [0], [4], [2], [6], [0], [6], [2], [4], [4], [5], [1], [0], [1], [5], [3], [2], [3], [6], [0], [0], [5], [1], [2], [6], [4], [2], [5], [3], [6], [3], [1], [3], [4], [2], [2], [5], [6], [1], [6], [4], [0], [0], [4], [5], [4], [2], [0], [6], [1], [5], [3], [1], [3], [6], [4], [1], [0], [3], [2], [5], [6], [2], [5], [0], [3], [6], [4], [6], [0], [0], [2], [5], [3], [4], [1], [1], [2], [3], [2], [3], [5], [4], [1], [0], [6], [1], [4], [5], [6], [3], [5], [4], [5], [0], [1], [2], [2], [0], [3], [6], [0], [6], [1], [4], [4], [2], [6], [5], [2], [0], [3], [1], [1], [1], [5], [0], [3], [4], [2], [5], [3], [4], [6], [0], [6], [1], [0], [5], [4], [2], [5], [3], [3], [2], [6], [1], [4], [0], [6], [4], [0], [5], [1], [2], [2], [6], [3], [0], [1], [3], [4], [3], [6], [0], [5], [2], [5], [1], [4], [3], [2], [6], [5], [1], [0], [5], [3], [0], [4], [6], [2], [6], [4], [6], [1], [1], [3], [5], [2], [0], [0], [4], [5], [4], [6], [0], [4], [5], [3], [2], [2], [3], [1], [1], [0], [2], [0], [3], [6], [5], [6], [2], [1], [3], [4], [5], [6], [4], [5], [6], [1], [0], [3], [2], [1], [0], [4], [3], [2], [6], [1], [4], [0], [1], [5], [5], [2], [4], [3], [6], [5], [6], [3], [2], [4], [1], [2], [0], [0], [5], [3], [2], [5], [6], [0], [0], [3], [1], [4], [6], [4], [1], [4], [5], [5], [3], [3], [4], [1], [2], [6], [0], [1], [2], [1], [5], [2], [3], [6], [3], [2], [0], [0], [4], [6], [3], [0], [5], [6], [4], [4], [1], [0], [5], [1], [2], [0], [5], [6], [6], [5], [4], [3], [2], [2], [3], [1], [4], [1], [4], [6], [6], [0], [5], [2], [1], [0], [3], [2], [3], [1], [5], [5], [3], [4], [2], [4], [1], [0], [6], [6], [5], [1], [3], [2], [0], [3], [2], [4], [5], [6], [0], [6], [0], [0], [2], [4], [3], [4], [5], [1], [6], [1], [1], [2], [4], [0], [5], [2], [3], [1], [3], [6], [5], [4], [6], [6], [4], [0], [3], [1], [2], [0], [5], [2], [3], [0], [0], [1], [3], [2], [6], [5], [5], [4], [4], [6], [1], [3], [4], [5], [2], [6], [2], [4], [3], [1], [0], [1], [5], [3], [2], [4], [5], [3], [1], [0], [6], [2], [0], [6], [5], [4], [5], [3], [0], [0], [6], [1], [4], [6], [2], [1], [0], [0], [2], [3], [4], [1], [6], [2], [4], [1], [5], [3], [5], [2], [6], [3], [4], [0], [4], [2], [6], [5], [1], [3], [5], [3], [2], [0], [6], [1], [4], [5], [1], [3], [0], [6], [2], [0], [1], [2], [6], [4], [1], [0], [5], [5], [4], [3], [1], [3], [5], [3], [4], [0], [4], [2], [2], [5], [6], [6], [5], [2], [1], [1], [3], [0], [4], [2], [0], [6], [6], [1], [0], [1], [4], [5], [4], [2], [3], [6], [3], [5], [3], [6], [6], [5], [0], [2], [4], [2], [3], [1], [0], [1], [6], [4], [6], [5], [1], [0], [2], [0], [3], [4], [5], [4], [4], [5], [1], [2], [6], [2], [0], [5], [3], [3], [2], [0], [4], [1], [6], [3], [6], [2], [5], [0], [5], [1], [3], [2], [0], [0], [3], [1], [5], [3], [4], [4], [1], [1], [4], [1], [3], [5], [1], [4], [2], [0], [2], [0], [3], [3], [3], [2], [5], [3], [4], [5], [3], [4], [1], [5], [0], [1], [3], [2], [5], [4], [1], [1], [2], [2], [0], [0], [0], [4], [0], [4], [1], [3], [1], [5], [5], [5], [2], [3], [5], [5], [1], [4], [5], [1], [2], [5], [2], [1], [5], [0], [1], [4], [0], [2], [5], [5], [3], [4], [3], [3], [3], [0], [1], [3], [3], [3], [1], [3], [2], [4], [2], [1], [1], [4], [3], [5], [0], [5], [2], [2], [3], [4], [1], [1], [1], [0], [0], [3], [4], [3], [5], [5], [4], [1], [5], [2], [2], [1], [2], [5], [3], [3], [3], [3], [5], [2], [2], [1], [4], [5], [4], [2], [1], [0], [4], [1], [4], [5], [2], [5], [4], [0], [2], [1], [0], [0], [5], [2], [4], [0], [5], [2], [0], [1], [4], [3], [2], [1], [2], [3], [1], [2], [3], [3], [5], [0], [3], [4], [2], [0], [4], [0], [5], [1], [1], [3], [3], [3], [2], [2], [0], [0], [3], [3], [1], [4], [2], [2], [2], [0], [3], [4], [0], [0], [5], [4], [5], [0], [4], [5], [1], [4], [5], [2], [1], [5], [0], [3], [0], [5], [1], [4], [2], [0], [3], [4], [6], [5], [2], [4], [5], [1], [3], [6], [0], [2], [3], [6], [0], [4], [6], [5], [1], [1], [2], [3], [1], [1], [2], [5], [4], [0], [6], [4], [3], [0], [5], [6], [2], [3], [4], [2], [6], [5], [1], [5], [4], [3], [4], [2], [3], [3], [0], [6], [6], [1], [0], [2], [5], [1], [5], [6], [4], [0], [3], [5], [6], [0], [1], [2], [1], [4], [1], [2], [3], [1], [5], [0], [3], [6], [4], [4], [5], [2], [3], [4], [0], [2], [6], [3], [1], [0], [5], [5], [2], [4], [6], [5], [3], [1], [2], [2], [0], [0], [1], [6], [6], [4], [3], [4], [0], [2], [4], [1], [3], [5], [5], [1], [6], [6], [5], [2], [2], [3], [1], [0], [5], [0], [4], [3], [6], [3], [0], [2], [5], [6], [1], [6], [4], [1], [0], [4], [5], [2], [6], [3], [3], [0], [4], [2], [4], [1], [1], [5], [0], [2], [5], [5], [3], [2], [3], [1], [6], [4], [6], [0], [4], [0], [6], [0], [5], [3], [4], [1], [2], [1], [6], [2], [3], [2], [1], [3], [4], [5], [4], [0], [1], [6], [5], [0], [6], [1], [2], [5], [4], [6], [5], [3], [3], [4], [2], [0], [4], [0], [5], [2], [3], [6], [0], [1], [2], [6], [3], [1], [4], [5], [4], [6], [1], [5], [3], [1], [0], [6], [0], [2], [5], [4], [1], [3], [3], [6], [5], [2], [2], [4], [0], [1], [3], [1], [5], [6], [0], [6], [2], [0], [4], [2], [1], [1], [3], [6], [3], [2], [4], [5], [5], [0], [0], [4], [2], [6], [4], [3], [1], [3], [2], [6], [0], [5], [4], [5], [6], [0], [5], [0], [1], [4], [3], [1], [3], [2], [2], [6], [1], [4], [0], [3], [1], [4], [5], [2], [0], [5], [6], [6], [1], [0], [5], [2], [2], [5], [3], [4], [3], [1], [4], [6], [2], [6], [0], [3], [5], [1], [3], [5], [4], [2], [6], [0], [1], [1], [2], [2], [0], [5], [6], [3], [0], [6], [4], [4], [5], [3], [5], [6], [4], [1], [1], [2], [4], [0], [3], [4], [3], [5], [6], [6], [0], [5], [0], [1], [3], [2], [2], [3], [4], [6], [6], [2], [0], [5], [1], [0], [4], [2], [1], [5], [0], [4], [0], [1], [3], [4], [1], [2], [6], [5], [3], [5], [2], [6], [4], [5], [6], [3], [2], [3], [1], [0], [0], [3], [6], [4], [2], [4], [2], [1], [5], [1], [6], [0], [5], [2], [3], [0], [0], [1], [5], [4], [4], [3], [6], [1], [1], [4], [6], [2], [3], [4], [0], [5], [6], [3], [2], [5], [2], [6], [1], [3], [2], [0], [4], [6], [5], [1], [3], [0], [5], [1], [0], [1], [6], [2], [4], [3], [5], [4], [0], [0], [2], [6], [3], [4], [3], [5], [5], [6], [1], [2], [0], [0], [6], [5], [6], [2], [4], [1], [1], [4], [2], [3], [3], [5], [2], [0], [4], [3], [4], [5], [1], [6], [0], [1], [6], [3], [5], [2], [4], [5], [3], [1], [6], [2], [4], [0], [2], [6], [2], [1], [4], [0], [0], [5], [3], [1], [6], [4], [6], [1], [0], [4], [3], [2], [6], [1], [3], [5], [0], [5], [3], [4], [6], [3], [5], [1], [2], [2], [5], [4], [0], [0], [1], [2], [5], [0], [6], [2], [1], [6], [4], [3], [4], [4], [5], [3], [6], [5], [1], [0], [1], [3], [0], [2], [1], [5], [6], [3], [5], [2], [6], [4], [0], [2], [3], [0], [0], [2], [3], [2], [6], [4], [6], [1], [4], [1], [5], [6], [3], [1], [5], [4], [2], [1], [5], [0], [4], [3], [3], [6], [0], [5], [2], [2], [0], [1], [3], [5], [6], [4], [1], [6], [0], [3], [2], [4], [1], [5], [2], [4], [6], [0], [0], [1], [4], [1], [5], [3], [4], [6], [3], [2], [0], [5], [4], [5], [3], [2], [3], [6], [1], [2], [0], [5], [6], [0], [3], [2], [6], [4], [4], [0], [2], [6], [1], [5], [1], [3], [3], [4], [5], [4], [0], [6], [5], [1], [0], [2], [1], [3], [5], [1], [6], [2], [3], [4], [0], [6], [5], [4], [2], [2], [3], [0], [1], [2], [6], [6], [1], [3], [0], [5], [4], [0], [6], [0], [5], [2], [3], [5], [6], [1], [4], [4], [1], [3], [3], [2], [1], [0], [5], [5], [4], [6], [2], [1], [4], [5], [2], [2], [0], [1], [3], [5], [6], [6], [3], [0], [4], [0], [6], [4], [6], [1], [3], [2], [5], [4], [0], [1], [1], [5], [3], [2], [6], [5], [2], [0], [1], [3], [4], [4], [2], [1], [5], [0], [2], [6], [3], [4], [0], [3], [6], [5], [6], [0], [3], [4], [4], [2], [6], [5], [1], [1], [0], [1], [3], [4], [2], [3], [1], [4], [2], [6], [0], [5], [5], [5], [2], [4], [6], [6], [0], [2], [1], [0], [3], [5], [3], [4], [1], [0], [2], [3], [6], [4], [6], [2], [3], [5], [2], [2], [6], [3], [5], [2], [4], [4], [6], [3], [5], [3], [4], [4], [4], [6], [5], [4], [6], [4], [1], [2], [3], [1], [5], [6], [2], [6], [3], [1], [5], [6], [2], [6], [1], [3], [2], [6], [5], [3], [6], [1], [4], [2], [4], [3], [5], [6], [3], [4], [2], [3], [6], [2], [4], [2], [4], [2], [3], [1], [6], [4], [2], [3], [4], [6], [1], [6], [4], [3], [6], [5], [6], [5], [6], [5], [6], [6], [5], [5], [6], [5], [6], [6], [5], [3], [5], [4], [4], [1], [4], [3], [0], [2], [5], [1], [0], [3], [3], [1], [4], [1], [2], [5], [4], [3], [3], [5], [3], [0], [1], [0], [1], [2], [2], [3], [4], [4], [2], [2], [0], [5], [1], [5], [2], [1], [5], [3], [3], [2], [5], [4], [1], [1], [0], [2], [0], [1], [4], [0], [5], [3], [4], [4], [0], [5], [2], [2], [0], [1], [4], [3], [4], [5], [2], [5], [3], [1], [0], [5], [4], [2], [3], [2], [4], [0], [1], [3], [1], [5], [3], [2], [0], [4], [3], [5], [4], [5], [4], [2], [1], [1], [5], [2], [1], [0], [5], [3], [4], [3], [2], [2], [2], [1], [3], [5], [3], [0], [5], [5], [3], [3], [5], [2], [1], [1], [4], [0], [2], [0], [0], [2], [1], [3], [2], [5], [3], [1], [1], [4], [5], [5], [2], [3], [3], [2], [0], [3], [1], [5], [4], [1], [0], [4], [0], [5], [2], [3], [4], [2], [5], [0], [2], [2], [1], [5], [1], [5], [5], [1], [0], [4], [3], [4], [2], [1], [3], [5], [0], [0], [1], [2], [1], [5], [4], [4], [2], [3], [4], [2], [0], [3], [2], [2], [3], [3], [3], [4], [4], [4], [5], [1], [4], [2], [0], [3], [5], [4], [0], [0], [1], [3], [1], [5], [4], [3], [5], [0], [2], [1], [4], [3], [1], [1], [1], [4], [0], [5], [4], [2], [0], [4], [0], [1], [1], [1], [1], [4], [5], [4], [1], [0], [4], [1], [3], [5], [0], [1], [3], [3], [0], [0], [3], [2], [2], [2], [4], [2], [4], [1], [3], [2], [2], [1], [0], [0], [5], [4], [5], [3], [3], [4], [3], [3], [5], [5], [0], [5], [5], [4], [2], [3], [3], [4], [2], [0], [1], [3], [5], [4], [4], [5], [1], [5], [1], [1], [1], [3], [3], [0], [5], [5], [2], [3], [0], [3], [1], [1], [4], [4], [3], [3], [0], [5], [5], [0], [1], [3], [4], [4], [5], [2], [4], [2], [4], [0], [1], [5], [2], [5], [2], [4], [0], [3], [5], [4], [5], [2], [0], [0], [2], [1], [5], [4], [2], [1], [2], [2], [4], [4], [2], [1], [0], [1], [3], [5], [0], [4], [3], [2], [0], [1], [2], [1], [0], [4], [4], [2], [1], [1], [2], [5], [5], [1], [5], [2], [3], [2], [0], [4], [1], [1], [0], [5], [3], [5], [3], [3], [3], [0], [2], [3], [0], [2], [1], [3], [5], [1], [5], [4], [0], [4], [1], [4], [1], [2], [2], [4], [4], [3], [1], [1], [4], [3], [4], [5], [5], [2], [2], [5], [4], [4], [5], [5], [0], [5], [3], [3], [0], [3], [2], [2], [2], [0], [3], [5], [4], [1], [4], [3], [5], [5], [2], [3], [5], [0], [2], [1], [3], [2], [5], [4], [0], [5], [4], [1], [1], [5], [4], [0], [2], [1], [0], [2], [4], [4], [2], [0], [1], [2], [0], [2], [2], [0], [4], [2], [4], [4], [2], [3], [3], [1], [2], [0], [0], [2], [1], [5], [3], [3], [3], [0], [5], [2], [2], [5], [2], [3], [3], [4], [5], [0], [0], [3], [3], [2], [1], [3], [3], [2], [4], [2], [4], [5], [0], [5], [0], [5], [2], [5], [3], [3], [4], [1], [3], [3], [5], [5], [3], [5], [5], [1], [4], [4], [4], [0], [2], [1], [1], [5], [4], [0], [3], [0], [5], [1], [2], [0], [5], [4], [0], [0], [2], [2], [0], [1], [0], [1], [1], [1], [0], [1], [5], [2], [2], [4], [3], [1], [3], [2], [3], [4], [3], [2], [5], [1], [0], [4], [0], [5], [1], [5], [5], [1], [3], [5], [4], [4], [3], [0], [3], [5], [2], [4], [4], [1], [2], [0], [0], [5], [3], [1], [5], [4], [5], [0], [1], [1], [3], [2], [3], [4], [4], [5], [1], [3], [4], [1], [1], [5], [3], [2], [1], [2], [5], [0], [0], [0], [2], [4], [1], [3], [3], [1], [3], [3], [0], [2], [4], [1], [1], [4], [5], [4], [3], [4], [1], [2], [5], [2], [4], [2], [1], [1], [5], [0], [5], [3], [5], [2], [2], [4], [1], [1], [2], [2], [2], [4], [3], [2], [0], [2], [2], [5], [4], [5], [3], [0], [1], [4], [2], [1], [1], [4], [4], [1], [3], [0], [3], [4], [1], [4], [4], [4], [0], [1], [3], [2], [3], [1], [4], [5], [4], [0], [2], [3], [2], [4], [3], [4], [1], [2], [5], [4], [2], [1], [5], [4], [0], [5], [1], [4], [2], [0], [1], [5], [5], [0], [5], [3], [4], [2], [3], [4], [2], [0], [5], [3], [2], [1], [3], [1], [0], [0], [0], [2], [0], [1], [5], [3], [3], [5], [5], [2], [4], [5], [3], [3], [2], [0], [5], [0], [2], [3], [4], [3], [3], [1], [2], [4], [4], [2], [0], [1], [3], [0], [0], [1], [2], [5], [3], [4], [2], [1], [3], [3], [2], [5], [1], [0], [3], [1], [2], [5], [3], [2], [0], [1], [4], [3], [5], [4], [0], [2], [2], [4], [1], [1], [0], [5], [5], [3], [3], [5], [4], [5], [5], [1], [2], [1], [3], [4], [0], [1], [1], [5], [4], [1], [5], [5], [1], [1], [0], [0], [5], [3], [5], [4], [3], [5], [2], [5], [2], [1], [2], [1], [3], [0], [1], [5], [0], [3], [5], [4], [3], [5], [1], [3], [3], [0], [0], [0], [5], [4], [2], [5], [3], [2], [0], [3], [1], [4], [5], [0], [5], [2], [4], [2], [3], [3], [4], [2], [1], [0], [5], [2], [4], [1], [3], [1], [4], [0], [4], [1], [4], [4], [2], [4], [4], [4], [4], [5], [2], [0], [0], [4], [1], [5], [2], [2], [2], [4], [4], [3], [0], [1], [5], [1], [1], [2], [2], [2], [1], [2], [2], [1], [2], [2], [3], [2], [5], [4], [3], [3], [5], [6], [5], [6], [5], [4], [3], [4], [3], [4], [4], [4], [5], [6], [3], [6], [6], [5], [6], [3], [5], [3], [5], [6], [6], [4], [4], [1], [4], [2], [2], [2], [3], [4], [2], [2], [4], [3], [4], [2], [3], [3], [1], [2], [3], [3], [1], [1], [2], [3], [3], [5], [4], [5], [4], [4], [4], [3], [2], [6], [3], [5], [1], [5], [6], [2], [3], [2], [2], [6], [2], [6], [1], [3], [2], [5], [1], [5], [3], [2], [6], [6], [5], [3], [2], [3], [5], [1], [1], [3], [6], [6], [1], [4], [5], [5], [2], [4], [5], [4], [6], [4], [6], [5], [6], [2], [3], [4], [1], [1], [1], [2], [5], [5], [2], [6], [2], [6], [5], [5], [3], [4], [2], [6], [1], [2], [4], [6], [6], [2], [4], [4], [3], [2], [2], [4], [6], [1], [6], [5], [2], [1], [1], [3], [4], [6], [6], [5], [5], [3], [5], [1], [2], [4], [1], [2], [5], [6], [4], [6], [4], [3], [3], [5], [4], [6], [4], [3], [6], [5], [5], [5], [6], [6], [3], [4], [2], [6], [4], [4], [5], [5], [3], [5], [3], [4], [5], [3], [4], [4], [2], [6], [4], [3], [5], [3], [6], [1], [2], [1], [5], [6], [6], [3], [6], [5], [3], [4], [6], [6], [4], [3], [6], [6], [4], [4], [5], [5], [2], [6], [5], [6], [2], [4], [1], [3], [2], [2], [4], [4], [6], [2], [5], [3], [3], [5], [4], [5], [3], [2], [3], [2], [1], [2], [5], [4], [1], [5], [6], [3], [3], [4], [4], [1], [6], [4], [6], [1], [1], [4], [3], [4], [1], [2], [5], [5], [3], [3], [3], [1], [4], [2], [2], [6], [3], [5], [3], [3], [6], [5], [5], [4], [3], [2], [5], [2], [2], [4], [2], [5], [6], [6], [5], [2], [4], [3], [4], [6], [2], [5], [5], [2], [4], [3], [4], [2], [4], [5], [2], [6], [5], [3], [1], [2], [3], [2], [2], [3], [4], [1], [4], [1], [1], [3], [3], [4], [2], [3], [1], [1], [4], [5], [1], [2], [5], [6], [3], [3], [6], [3], [4], [4], [6], [4], [6], [3], [3], [2], [2], [4], [6], [1], [3], [2], [4], [1], [5], [3], [2], [2], [1], [2], [2], [5], [4], [6], [6], [3], [6], [2], [6], [6], [5], [2], [2], [6], [5], [5], [2], [6], [6], [6], [1], [2], [1], [1], [6], [5], [1], [5], [5], [6], [1], [2], [4], [5], [5], [2], [6], [6], [3], [5], [5], [4], [3], [5], [5], [3], [6], [3], [4], [5], [6], [2], [3], [4], [4], [4], [4], [6], [5], [3], [4], [5], [6], [4], [3], [6], [6], [5], [3], [5], [4], [5], [4], [6], [3], [2], [4], [4], [6], [3], [5], [5], [2], [2], [2], [4], [4], [6], [5], [1], [6], [4], [1], [3], [2], [2], [4], [6], [6], [5], [2], [5], [5], [6], [1], [1], [3], [3], [1], [3], [6], [3], [3], [2], [4], [3], [2], [5], [4], [3], [2], [6], [4], [2], [3], [4], [5], [1], [1], [3], [3], [5], [6], [2], [2], [5], [1], [3], [2], [1], [4], [2], [5], [4], [4], [5], [3], [2], [1], [3], [5], [4], [5], [5], [2], [5], [1], [1], [3], [2], [4], [3], [1], [2], [6], [1], [2], [5], [3], [4], [5], [6], [4], [3], [3], [3], [2], [6], [6], [5], [5], [2], [2], [6], [4], [3], [4], [1], [5], [2], [6], [4], [6], [4], [5], [4], [3], [5], [6], [6], [3], [2], [5], [5], [4], [1], [2], [3], [6], [4], [4], [5], [2], [6], [6], [4], [2], [4], [5], [5], [2], [4], [3], [3], [3], [3], [2], [5], [1], [4], [1], [6], [2], [3], [6], [6], [2], [4], [1], [3], [1], [4], [2], [6], [5], [4], [2], [5], [6], [2], [5], [3], [3], [1], [1], [1], [6], [3], [6], [2], [2], [3], [3], [4], [2], [6], [6], [4], [4], [2], [3], [3], [4], [3], [1], [6], [4], [6], [4], [2], [1], [6], [3], [3], [1], [3], [2], [6], [6], [4], [3], [2], [5], [3], [5], [4], [6], [2], [2], [1], [1], [2], [6], [5], [2], [1], [4], [3], [5], [3], [6], [4], [4], [3], [6], [2], [2], [5], [6], [5], [1], [2], [2], [2], [5], [5], [6], [5], [6], [1], [1], [6], [3], [5], [2], [2], [1], [3], [3], [4], [2], [5], [4], [4], [6], [6], [2], [5], [6], [5], [3], [1], [6], [3], [5], [3], [2], [6], [1], [6], [4], [4], [4], [1], [2], [5], [2], [6], [6], [4], [2], [4], [6], [1], [5], [6], [1], [1], [1], [6], [5], [5], [6], [4], [2], [5], [5], [6], [4], [2], [5], [5], [4], [2], [3], [3], [5], [5], [4], [3], [4], [4], [6], [2], [5], [6], [5], [6], [4], [5], [6], [4], [3], [4], [3], [1], [6], [6], [3], [1], [6], [2], [1], [5], [4], [3], [3], [3], [1], [5], [5], [3], [2], [1], [4], [6], [3], [3], [3], [3], [4], [6], [2], [6], [2], [2], [5], [5], [2], [4], [4], [4], [6], [4], [5], [6], [5], [2], [4], [6], [6], [3], [5], [5], [4], [2], [5], [3], [2], [6], [4], [6], [3], [5], [3], [4], [3], [6], [6], [2], [4], [5], [2], [3], [1], [2], [5], [4], [2], [3], [5], [3], [2], [5], [3], [6], [5], [6], [3], [4], [3], [3], [4], [1], [2], [6], [1], [6], [6], [5], [2], [1], [2], [4], [5], [6], [4], [5], [1], [6], [4], [2], [3], [6], [3], [4], [3], [1], [1], [3], [4], [2], [6], [5], [3], [2], [6], [2], [3], [3], [4], [5], [2], [2], [1], [4], [1], [5], [2], [4], [1], [6], [4], [5], [5], [2], [3], [6], [5], [5], [4], [4], [5], [6], [5], [1], [3], [6], [4], [1], [3], [3], [1], [4], [2], [2], [5], [1], [4], [4], [2], [4], [4], [3], [3], [5], [5], [5], [2], [6], [6], [4], [2], [3], [1], [5], [3], [2], [3], [2], [5], [4], [2], [5], [5], [6], [6], [6], [3], [3], [2], [1], [4], [2], [1], [5], [1]]'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save X,Y arrays as lists to json files.\n",
        "\n",
        "x_data = X.tolist() \n",
        "x_path = '/content/drive/My Drive/Colab_Notebooks/X_datanew.json' # FILE SAVE PATH\n",
        "dump(obj = x_data, fp = x_path)\n",
        "\n",
        "y_data = Y.tolist() \n",
        "y_path = '/content/drive/My Drive/Colab_Notebooks/Y_datanew.json' # FILE SAVE PATH\n",
        "dump(obj = y_data, fp = y_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oy53CmsODtSQ"
      },
      "outputs": [],
      "source": [
        "# Load X,Y json files back into lists, convert to np.arrays\n",
        "\n",
        "x_path = '/content/drive/My Drive/Colab_Notebooks/X_datanew.json' # FILE LOAD PATH\n",
        "X = load(x_path)\n",
        "X = np.asarray(X, dtype = 'float32')\n",
        "\n",
        "y_path = '/content/drive/My Drive/Colab_Notebooks/Y_datanew.json' # FILE LOAD PATH\n",
        "Y = load(y_path)\n",
        "Y = np.asarray(Y, dtype = 'int8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "h1Photkwq-bw"
      },
      "outputs": [],
      "source": [
        "# Split to train, validation, and test sets.\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_tosplit, y_train, y_tosplit = train_test_split(X, Y, test_size = 0.125, random_state = 1)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_tosplit, y_tosplit, test_size = 0.304, random_state = 1)\n",
        "\n",
        "#'One-hot' vectors for Y: emotion \n",
        "\n",
        "y_train_class = tf.keras.utils.to_categorical(y_train, 7, dtype = 'int8')\n",
        "y_val_class = tf.keras.utils.to_categorical(y_val, 7, dtype = 'int8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NgRlZBJbMHvX",
        "outputId": "c32095ff-e98e-46e4-a156-ccb0762286e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4371, 448, 27)\n",
            "(435, 448, 27)\n",
            "(190, 448, 27)\n"
          ]
        }
      ],
      "source": [
        "# x_train, x_val, and x_test shape check.\n",
        "print(np.shape(x_train))\n",
        "print(np.shape(x_val))\n",
        "print(np.shape(x_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aW4qJ9VogZJ2",
        "outputId": "92bb95a9-ef69-493a-ec16-b30135074961"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'{\"__ndarray__\": [[6], [4], [4], [0], [5], [2], [5], [0], [1], [6], [2], [3], [6], [5], [2], [4], [3], [4], [2], [4], [2], [0], [1], [2], [5], [2], [6], [1], [6], [2], [1], [5], [1], [5], [4], [4], [5], [1], [0], [0], [5], [2], [1], [1], [1], [2], [3], [5], [1], [1], [3], [1], [1], [0], [3], [0], [4], [4], [6], [2], [4], [0], [6], [1], [1], [6], [0], [3], [1], [6], [4], [5], [6], [5], [0], [2], [3], [3], [3], [1], [1], [5], [4], [1], [0], [0], [0], [2], [0], [5], [5], [2], [4], [5], [3], [4], [5], [6], [2], [1], [6], [2], [3], [1], [2], [1], [4], [4], [2], [4], [4], [6], [3], [5], [4], [2], [0], [4], [5], [3], [1], [3], [5], [1], [2], [4], [2], [0], [1], [4], [1], [1], [2], [0], [1], [3], [2], [2], [2], [3], [3], [5], [2], [2], [0], [0], [0], [5], [2], [3], [2], [0], [1], [4], [1], [5], [2], [2], [0], [3], [6], [3], [3], [1], [3], [1], [1], [4], [5], [5], [3], [2], [4], [2], [2], [1], [4], [6], [1], [4], [3], [3], [2], [4], [0], [5], [4], [5], [3], [3]], \"dtype\": \"int8\", \"shape\": [190, 1], \"Corder\": true}'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save x_test, y_test to JSON.\n",
        "\n",
        "file_path = 'x_test_data.json'\n",
        "dump(obj = x_test, fp = file_path)\n",
        "\n",
        "file_path = 'y_test_data.json'\n",
        "dump(obj = y_test, fp = file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1ROkmISHZCkM"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras import callbacks "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3DroQ71fXxPN",
        "outputId": "dc156949-58b7-47e3-e802-9870d48d2616"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 448, 64)           23552     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                33024     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 7)                 455       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 57,031\n",
            "Trainable params: 57,031\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "ename": "OSError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-045c5968f651>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Callbacks functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mcheckpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/Colab_Notebooks/best_weights.hdf5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, **kwds)\u001b[0m\n\u001b[1;32m    425\u001b[0m                                fapl, fcpl=make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[1;32m    426\u001b[0m                                fs_persist=fs_persist, fs_threshold=fs_threshold),\n\u001b[0;32m--> 427\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '/content/drive/My Drive/Colab_Notebooks/best_weights.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ],
      "source": [
        "# Initializing the model\n",
        "\n",
        "model = Sequential() #relu , siqmoid , software\n",
        "model.add(layers.LSTM(64, return_sequences = True, input_shape=(X.shape[1:3])))\n",
        "model.add(layers.LSTM(64))\n",
        "model.add(layers.Dense(7, activation = 'relu'))\n",
        "\n",
        "\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "batch_size = 23\n",
        "\n",
        "# Callbacks functions\n",
        "checkpoint_path = '/content/drive/My Drive/Colab_Notebooks/best_weights.hdf5'\n",
        "model.load_weights(checkpoint_path)\n",
        "\n",
        "\n",
        "#-> Save the best weights\n",
        "mcp_save = callbacks.ModelCheckpoint(checkpoint_path, save_best_only=True,\n",
        "                           monitor='val_categorical_accuracy',\n",
        "                           mode='max')\n",
        "#-> Reduce learning rate after 100 epoches without improvement.\n",
        "rlrop = callbacks.ReduceLROnPlateau(monitor='val_categorical_accuracy', \n",
        "                                    factor=0.1, patience=100)\n",
        "                             \n",
        "# Compile & train   \n",
        "model.compile(loss='categorical_crossentropy', \n",
        "                optimizer='RMSProp', \n",
        "                metrics=['categorical_accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train_class, #shuffle= True, btsh2lb al data\n",
        "                      epochs=340, batch_size = batch_size,   #340   \n",
        "                      validation_data = (x_val, y_val_class), \n",
        "                      callbacks = [mcp_save, rlrop])\n",
        "# Define the best weights to the model.\n",
        "model.load_weights(checkpoint_path)\n",
        "\n",
        "print(f\"Running time: {(toc - tic)/60:0.4f} minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lrq5r7wpufzS"
      },
      "outputs": [],
      "source": [
        "# checkpoint_path = '/content/drive/My Drive/Colab_Notebooks/best_weights.hdf5'\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(layers.LSTM(64, return_sequences = True, input_shape=(X.shape[1:3])))\n",
        "# model.add(layers.LSTM(64))\n",
        "# model.add(layers.Dense(7, activation = 'softmax'))\n",
        "\n",
        "# model.compile(loss='categorical_crossentropy', \n",
        "#                 optimizer='RMSProp', \n",
        "#                 metrics=['categorical_accuracy'])\n",
        "\n",
        "\n",
        "# model.load_weights(checkpoint_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "t3xnV1S7ra_Y"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nu3eLmdtNlCF"
      },
      "outputs": [],
      "source": [
        "# Loss, Accuracy presentation\n",
        "\n",
        "# Plot history: Loss\n",
        "plt.plot(history.history['loss'], label='Loss (training data)')\n",
        "plt.plot(history.history['val_loss'], label='Loss (validation data)')\n",
        "plt.title('Loss for train and validation')\n",
        "plt.ylabel('Loss value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()\n",
        "\n",
        "#Plot history: Accuracy\n",
        "plt.plot(history.history['categorical_accuracy'], label='Acc (training data)')\n",
        "plt.plot(history.history['val_categorical_accuracy'], label='Acc (validation data)')\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Acc %')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Bc6qcBGOMHv7"
      },
      "outputs": [],
      "source": [
        "# Validation score\n",
        "loss,acc = model.evaluate(x_val, y_val_class, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XhR-4z86VPCy"
      },
      "outputs": [],
      "source": [
        "y_val_class.shape\n",
        "x_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3Icd1yFHra_Z"
      },
      "outputs": [],
      "source": [
        "# Validation Confusion matrix\n",
        "\n",
        "y_val_class = np.argmax(y_val_class, axis=1)\n",
        "predictions = model.predict(x_val)\n",
        "y_pred_class = np.argmax(predictions, axis=1)\n",
        "cm=confusion_matrix(y_val_class, y_pred_class)\n",
        "\n",
        "# index = ['neutral', 'calm', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']  \n",
        "# columns = ['neutral', 'calm', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']  \n",
        "\n",
        "index = ['neutral', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']  \n",
        "columns = ['neutral', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']  \n",
        "\n",
        "cm_df = pd.DataFrame(cm,index,columns)\n",
        "plt.figure(figsize=(12,7))\n",
        "ax = plt.axes()\n",
        "\n",
        "sns.heatmap(cm_df, ax = ax, cmap = 'PuBu', fmt=\"d\", annot=True) \n",
        "ax.set_ylabel('True emotion')\n",
        "ax.set_xlabel('Predicted emotion')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "j70DNePpra_c"
      },
      "outputs": [],
      "source": [
        "# Validation set prediction accuracy rates\n",
        "\n",
        "values = cm.diagonal()\n",
        "print(values) \n",
        "row_sum = np.sum(cm,axis=1)\n",
        "print(row_sum)\n",
        "acc = values / row_sum\n",
        "\n",
        "print('Validation set predicted emotions accuracy:')\n",
        "for e in range(0, len(values)):\n",
        "    print(index[e],':', f\"{(acc[e]):0.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8ybMruIrra_d"
      },
      "outputs": [],
      "source": [
        "# Saving model & weights\n",
        "\n",
        "from keras.models import model_from_json\n",
        "from keras.models import load_model\n",
        "\n",
        "model_json = model.to_json()\n",
        "saved_model_path = '/content/drive/My Drive/Colab_Notebooks/model8723.json'\n",
        "saved_weights_path = '/content/drive/My Drive/Colab_Notebooks/model8723_weights.h5'\n",
        "\n",
        "\n",
        "with open(saved_model_path, \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "    \n",
        "model.save_weights(saved_weights_path)\n",
        "print(\"Saved model to disk\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7CvsDF6cOa3z"
      },
      "outputs": [],
      "source": [
        "# Reading the model from JSON file\n",
        "\n",
        "saved_model_path = '/content/drive/MyDrive/Colab_Notebooks/model8723.json'\n",
        "saved_weights_path = '/content/drive/MyDrive/Colab_Notebooks/model8723_weights.h5'\n",
        "\n",
        "with open(saved_model_path , 'r') as json_file:\n",
        "    json_savedModel = json_file.read()\n",
        "    \n",
        "# Loading the model architecture, weights\n",
        "model = tf.keras.models.model_from_json(json_savedModel)\n",
        "model.load_weights(saved_weights_path)\n",
        "\n",
        "# Compiling the model with similar parameters as the original model.\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "                optimizer='RMSProp', \n",
        "                metrics=['categorical_accuracy'])\n",
        "\n",
        "# Model's structure visualization\n",
        "tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9aw0_8VfOa30"
      },
      "outputs": [],
      "source": [
        "# Loading x_test, y_test json files, and converting to np.arrays\n",
        "\n",
        "x_test = load( 'x_test_data.json')\n",
        "x_test = np.asarray(x_test).astype('float32')\n",
        "\n",
        "y_test = load('y_test_data.json')\n",
        "y_test = np.asarray(y_test).astype('int8')\n",
        "\n",
        "y_test_class = tf.keras.utils.to_categorical(y_test, 7, dtype = 'int8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "b56-z_GUOa31"
      },
      "outputs": [],
      "source": [
        "loss, acc = model.evaluate(x_test, y_test_class, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9ssa4HRVOa31"
      },
      "outputs": [],
      "source": [
        "# Test set Confusion matrix\n",
        "print(x_test.shape)\n",
        "y = np.argmax(y_test_class, axis=1)\n",
        "predictions = model.predict(x_test)\n",
        "y_pred_class = np.argmax(predictions, axis=1)\n",
        "\n",
        "cm=confusion_matrix(y, y_pred_class)\n",
        "\n",
        "# index = ['neutral', 'calm', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']  \n",
        "# columns = ['neutral', 'calm', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']  \n",
        "\n",
        "index = ['neutral', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']  \n",
        "columns = ['neutral', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised']  \n",
        "\n",
        " \n",
        "cm_df = pd.DataFrame(cm,index,columns)                      \n",
        "plt.figure(figsize=(12,7))\n",
        "ax = plt.axes()\n",
        "\n",
        "sns.heatmap(cm_df, ax = ax, cmap = 'BuGn', fmt=\"d\", annot=True)\n",
        "ax.set_ylabel('True emotion')\n",
        "ax.set_xlabel('Predicted emotion')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Hwbkmv2yOa32"
      },
      "outputs": [],
      "source": [
        "  # Test set prediction accuracy rates\n",
        "\n",
        "values = cm.diagonal()\n",
        "row_sum = np.sum(cm,axis=1)\n",
        "acc = values / row_sum\n",
        "\n",
        "print('Test set predicted emotions accuracy:')\n",
        "for e in range(0, len(values)):\n",
        "    print(index[e],':', f\"{(acc[e]):0.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DmHZYHVErkQ2"
      },
      "outputs": [],
      "source": [
        "subdir = '/content/drive/MyDrive/Colab_Notebooks/AudioFiles/Used Dataset'\n",
        "traning = [\"03-01-07-02-01-01-23.wav\", \"1013_TSI_SAD_XX.wav\", \"YAF_young_happy.wav\"]\n",
        "\n",
        "# subdir = \"/content/drive/MyDrive/Colab_Notebooks/AudioFiles\"\n",
        "# traning = [\"ode.wav\"]\n",
        "\n",
        "for file in traning:\n",
        "    rms = []\n",
        "    zcr = []\n",
        "    mfcc = []\n",
        "    chroma = []\n",
        "    # emotions = []\n",
        "\n",
        "    # Initialize variables\n",
        "    total_length = 228864 #228864  #305152  #5005152    # desired frame length for all of the audio samples.\n",
        "    frame_length = 2048\n",
        "    hop_length = 512\n",
        "\n",
        "\n",
        "    # Fetch the sample rate.\n",
        "    _, sr = librosa.load(path = os.path.join(subdir,file), sr = None) # sr (the sample rate) is used for librosa's MFCCs. '_' is irrelevant.\n",
        "    # Load the audio file.\n",
        "    rawsound = AudioSegment.from_file(os.path.join(subdir,file)) \n",
        "    # Normalize the audio to +5.0 dBFS.\n",
        "    normalizedsound = effects.normalize(rawsound, headroom = 5.0) \n",
        "    # Transform the normalized audio to np.array of samples.\n",
        "    normal_x = np.array(normalizedsound.get_array_of_samples(), dtype = 'float32')\n",
        "    # Trim silence from the beginning and the end.\n",
        "    xt,  index = librosa.effects.trim(normal_x, top_db=30)\n",
        "    # Pad for duration equalization.\n",
        "    # print(xt.shape)\n",
        "    padded_x = np.pad(xt, (0, total_length-len(xt)), 'constant')\n",
        "    # Noise reduction.\n",
        "    final_x = nr.reduce_noise(y=padded_x,y_noise=padded_x, sr=sr)\n",
        "\n",
        "    # Features extraction \n",
        "    f1 = librosa.feature.rms(final_x, frame_length=frame_length, hop_length=hop_length) # Energy - Root Mean Square\n",
        "    f2 = librosa.feature.zero_crossing_rate(final_x , frame_length=frame_length, hop_length=hop_length, center=True) # ZCR\n",
        "    f3 = librosa.feature.mfcc(final_x, sr=sr, n_mfcc=13, hop_length = hop_length) # MFCC\n",
        "    f4 = librosa.feature.chroma_stft(final_x,sr=sr) #chroma\n",
        "      \n",
        "\n",
        "    # Emotion extraction from the different databases\n",
        "    # if (find_emotion_T(file) != \"-1\"): #TESS database validation\n",
        "    #       name = find_emotion_T(file)\n",
        "    # else:                              #RAVDESS database validation\n",
        "    #       name = file[6:8]                      \n",
        "    # print(name);\n",
        "    # Filling the data lists  \n",
        "    rms.append(f1)\n",
        "    zcr.append(f2)\n",
        "    mfcc.append(f3)\n",
        "    chroma.append(f4)\n",
        "    # emotions.append((name)) \n",
        "\n",
        "    # Adjusting features shape to the 3D format: (batch, timesteps, feature)\n",
        "\n",
        "    f_rms = np.asarray(rms).astype('float32')\n",
        "    f_rms = np.swapaxes(f_rms,1,2)\n",
        "    f_zcr = np.asarray(zcr).astype('float32')\n",
        "    f_zcr = np.swapaxes(f_zcr,1,2)\n",
        "    f_mfccs = np.asarray(mfcc).astype('float32')\n",
        "    f_mfccs = np.swapaxes(f_mfccs,1,2)\n",
        "    f_chroma = np.asarray(chroma).astype('float32')\n",
        "    f_chroma = np.swapaxes(f_chroma,1,2)\n",
        "\n",
        "    # Concatenating all features to 'X' variable.\n",
        "    X = np.concatenate(( f_rms,f_zcr,f_mfccs,  f_chroma), axis=2) #,\n",
        "\n",
        "    # Preparing 'Y' as a 2D shaped variable.\n",
        "    # Y = np.asarray(emotions).astype('int8')\n",
        "    # Y = np.expand_dims(Y, axis=1)\n",
        "\n",
        "\n",
        "    # y = np.argmax(Y, axis=1)\n",
        "    predictions = model.predict(X)\n",
        "    # y_pred_class = np.argmax(predictions, axis=1)\n",
        "\n",
        "    emotions = {\n",
        "        0 : 'neutral',\n",
        "        1 : 'happy',\n",
        "        2 : 'sad',\n",
        "        3 : 'angry',\n",
        "        4 : 'fearful',  \n",
        "        5 : 'disgust',\n",
        "        6 : 'suprised'   \n",
        "    }  \n",
        "    # emo_list = list(emotions.values())\n",
        "\n",
        "    max_emo = np.argmax(predictions)\n",
        "    print('max emotion:', emotions.get(max_emo,-1))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "GD 2_model.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}